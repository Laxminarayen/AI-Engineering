{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interview Questions LeetCode.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTSNO0sjF0+7LallSeYMi+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plthiyagu/AI-Engineering/blob/master/15-LeetCode/Interview_Questions_LeetCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIjrmQMFk6fx"
      },
      "source": [
        "Write a function that checks if a list of integers is normally distributed. Specifically given a list of 100 numbers, write a function that returns a score that measures the deviation from normality. I.E. a normally distributed list of integers would return 0. (Amazon | Data Scientist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dcighTMk_oa"
      },
      "source": [
        "I have used the three sigma thumb rule of normal distribution which means the values within one standard deviation of the mean account for about 68% of the list while within two standard deviations account for about 95% and within three standard deviations account for about 99.7%.\n",
        "a. Calculate mean and standard deviation of the list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVdAoPZTk5kR"
      },
      "source": [
        "def normality_test(sample_list):\n",
        "    l = len(sample_list)\n",
        "    avg_num = sum(sample_list)/l\n",
        "    sigma_num = (sum((x-avg_num)**2 for x in sample_list) / l) ** .5"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXyNb-JKlKtm"
      },
      "source": [
        "b. Check the percentage of values in each standard deviation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "006O9YyElE4E"
      },
      "source": [
        "def normality_test(sample_list):\n",
        "  num1 = 0\n",
        "  num2 = 0\n",
        "  num3 = 0\n",
        "  for x in sample_list:\n",
        "    if (x < sigma_num + avg_num) and (x > avg_num - sigma_num):\n",
        "      num1 += 1\n",
        "    if (x < (2*sigma_num) + avg_num) and (x > (avg_num - (2*sigma_num))):\n",
        "      num2 += 1\n",
        "    if (x < (3*sigma_num) + avg_num) and (x > (avg_num - (3*sigma_num))):\n",
        "      num3+= 1\n",
        "  d1 = num1/l\n",
        "  d2 = num2/l\n",
        "  d3 = num3/l"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qLtrA-Klx_B"
      },
      "source": [
        "c. Now that we have percentage of values of 1SD, 2SD and 3SD, we can check if the values of 1SD ≤ 0.68, 2SD ≤ 0.95 and 3SD ≤ 0.997. If the condition satisfies then we have a Normal Distribution else not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsYL2aTXl1KQ"
      },
      "source": [
        "2. Write a function that can take a string and return a list of bigrams. (Indeed, Microsoft, Facebook | Roles: Research Scientist, ML Engineer, Data Scientist)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUYwQ3FClO5t",
        "outputId": "30036a2b-d14c-4375-a0a4-fa8f73a45780"
      },
      "source": [
        "text = ['Have free hours and love children?',  'Drive kids to school', 'soccer practice and other activities.'] \n",
        "output = [] \n",
        "for l in text:    \n",
        "    for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:]):\n",
        "        output.append(b) \n",
        "print(output)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Have', 'free'), ('free', 'hours'), ('hours', 'and'), ('and', 'love'), ('love', 'children?'), ('Drive', 'kids'), ('kids', 'to'), ('to', 'school'), ('soccer', 'practice'), ('practice', 'and'), ('and', 'other'), ('other', 'activities.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P3kcHNGl7qq"
      },
      "source": [
        "3. Let’s say you’re given a list of standardized test scores from high schoolers from grades 9 to 12.\n",
        "Given the dataset, write code in Pandas to return the cumulative percentage of students that received scores within the buckets of <50, <75, <90, <100. (Google | Data Scientist)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "5G6hyGUml4ki",
        "outputId": "42c25cd9-a084-4ed0-93c7-2b60ff2687db"
      },
      "source": [
        "import pandas as pd\n",
        "data = {'user_id':  [1,2,3,4,5,6,7,8,9,10,11,12],\n",
        "        'grade': [10,10,11,10,11,10,10,10,10,10,10,10],\n",
        "        'test_score': [85,60,90,30,99,44,84,93,90,98,89,78]\n",
        "        }\n",
        "df = pd.DataFrame(data,columns = ['user_id' ,  'grade' , 'test_score'] )\n",
        "# print(df)\n",
        "bins = [0, 50, 75, 90, 100]\n",
        "labels=['<50','<75','<90' , '<100']\n",
        "df['test_score'] = pd.cut(df['test_score'], bins,labels=labels)\n",
        "numer = df.groupby(['grade','test_score'])['user_id'].count()\n",
        "denom = df.groupby(['grade'])['user_id'].count()\n",
        "df = numer/denom\n",
        "df = df.reset_index()\n",
        "df['Percentage']=(df.groupby(['grade'])['user_id'].cumsum()*100).astype('str')+\"%\"\n",
        "df=df[['grade','test_score','Percentage']]\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>grade</th>\n",
              "      <th>test_score</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;50</td>\n",
              "      <td>20.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;75</td>\n",
              "      <td>30.000000000000004%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;90</td>\n",
              "      <td>80.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>100.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>&lt;50</td>\n",
              "      <td>0.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>&lt;75</td>\n",
              "      <td>0.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11</td>\n",
              "      <td>&lt;90</td>\n",
              "      <td>50.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>100.0%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   grade test_score           Percentage\n",
              "0     10        <50                20.0%\n",
              "1     10        <75  30.000000000000004%\n",
              "2     10        <90                80.0%\n",
              "3     10       <100               100.0%\n",
              "4     11        <50                 0.0%\n",
              "5     11        <75                 0.0%\n",
              "6     11        <90                50.0%\n",
              "7     11       <100               100.0%"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjdDRjcnmGNs"
      },
      "source": [
        "4. There are two lists of dictionaries representing friendship beginnings and endings: friends_added and friends_removed. Each dictionary contains the user_ids and created_at time of the friendship beginning /ending .\n",
        "Write a function to generate an output which lists the pairs of friends with their corresponding timestamps of the friendship beginning and then the timestamp of the friendship ending.\n",
        "Note: There can be multiple instances over time when two people became friends and unfriended; only output lists when a corresponding friendship was removed. (Facebook | Data Scientist)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lidTAcamBsY"
      },
      "source": [
        "friends_added = [{'user_ids': [1, 2], 'created_at': '2020-01-01'},\n",
        "                 {'user_ids': [3, 2], 'created_at': '2020-01-02'},\n",
        "                 {'user_ids': [2, 1], 'created_at': '2020-02-02'},\n",
        "                 {'user_ids': [4, 1], 'created_at': '2020-02-02'}]\n",
        "\n",
        "friends_removed = [{'user_ids': [2, 1], 'created_at': '2020-01-03'},\n",
        "                   {'user_ids': [2, 3], 'created_at': '2020-01-05'},\n",
        "                   {'user_ids': [1, 2], 'created_at': '2020-02-05'}]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8vitJWKmP7h"
      },
      "source": [
        "It is important to note that we are only looking for friendships that have an end date. Because of this, every friendship that will be in our final output is present in the friends_removed list. So if we start by iterating through the friends_removed dictionary, we will get the id pair and the end date of each listing in our final output. Now, we will need to find the corresponding start date for each end date by checking that the created_at date of friends_added for a particular user_id is always smaller than the created_at date of friends_removed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEkY0Ba9mKVR"
      },
      "source": [
        "def friendship_timeline(fd_added, fd_removed):\n",
        "    friendship = []\n",
        "    for rem in fd_removed:\n",
        "        for add in fd_added:\n",
        "            if sorted(rem['user_ids']) == sorted(add['user_ids']):\n",
        "                fd_added.remove(add)\n",
        "                friendship.append({\n",
        "                    'user_ids': sorted(rem['user_ids']),\n",
        "                    'start_date': add['created_at'],\n",
        "                    'end_date': rem['created_at']\n",
        "                })\n",
        "                break\n",
        "    return sorted(friendship, key=lambda x: x['user_ids'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLySBkv-mZXN"
      },
      "source": [
        "5. Every night between 7pm and midnight, two computing jobs from two different sources are randomly started with each one lasting an hour. Unfortunately, when the jobs simultaneously run, they cause a failure in some of the company’s other nightly jobs, resulting in downtime for the company that costs $1000.\n",
        "The CEO needs a single number representing the annual (365 days) cost of this problem. Write a function to simulate this problem and output an estimated cost. Bonus — How this can be solved using probability? (Wealthfront | Roles: Data Analysts, Data Scientist, Business Intelligence)\n",
        "Answer: Within 7pm and midnight, we have 5*60*60 seconds. We can do simulation to get an approximation of the probability that overlap will occur between the two jobs. We will generate two random numbers and check if they overlap and append the values 1 or 0 to our array. Finally we will consider the mean to get the answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tIMVTHXmU5E",
        "outputId": "7fa56ffb-caa5-4830-c3b3-2c20866abfd0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "task1 = np.random.randint(0, 5*60*60, size = 10000000)\n",
        "task2 = np.random.randint(0, 5*60*60, size = 10000000)\n",
        "data = pd.DataFrame(\n",
        "    {'task1_start': task1,\n",
        "     'task2_start': task2,\n",
        "    })\n",
        "data['overlap'] = np.where(np.abs(data.task1_start - data.task2_start) <=3600, 1, 0)\n",
        "print(data['overlap'].mean())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3598396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v13MxIOhmnpE"
      },
      "source": [
        "6. Given a list of timestamps in sequential order, return a list of lists grouped by week (7 days) using the first timestamp as the starting point. (Amazon, Adobe | Roles: Data Scientist, Data Analyst, Research Scientist)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOeRrlhlmjsM",
        "outputId": "9c23a961-0ecf-4371-d6a3-764e987f06a7"
      },
      "source": [
        "import datetime\n",
        "class Solution:\n",
        "  def weekly_aggregate(self, ts):\n",
        "      if ts == None or len(ts) == 0: return -1\n",
        "      output = [[ts[0]]]\n",
        "      count = 0\n",
        "      \n",
        "      for idx in range(1, len(ts)):\n",
        "          if self.WkNum(ts[idx]) == self.WkNum(ts[idx - 1]):\n",
        "              output[count].append(ts[idx])\n",
        "          else:\n",
        "              count += 1\n",
        "              output.append([ts[idx]])\n",
        "      return output\n",
        "  def WkNum(self, time_text):\n",
        "      t = datetime.datetime.strptime(time_text, \"%Y-%m-%d\")\n",
        "      wk = (t - datetime.datetime(t.year, 1, 1)).days // 7 + 1\n",
        "      return wk\n",
        "      \n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "    s = Solution()\n",
        "    ts = ['2019-01-01', \n",
        "        '2019-01-02',\n",
        "        '2019-01-08', \n",
        "        '2019-02-01', \n",
        "        '2019-02-02',\n",
        "        '2019-02-05']\n",
        "    print(s.weekly_aggregate(ts))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['2019-01-01', '2019-01-02'], ['2019-01-08'], ['2019-02-01', '2019-02-02'], ['2019-02-05']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NDPfe55GLEF"
      },
      "source": [
        "7. Write a function that takes in a list of dictionaries with a key and list of integers and returns a dictionary with the standard deviation of each list. (Snapchat, Tinder | Roles: Data Scientist, Data Analyst)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WVuwjxkmru2"
      },
      "source": [
        "def std(data):\n",
        "    mu = np.average(data)\n",
        "    output = np.sqrt(sum((x-mu)**2 for x in data) / len(data))\n",
        "    return output\n",
        "def get_stddev(input):\n",
        "    new_dict = {}\n",
        "    for x in input:\n",
        "        new_dict[x.get('key')] = std(x.get('values'))\n",
        "    return new_dict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF5cyZVsGSYZ"
      },
      "source": [
        "8. Write a function to calculate the root mean squared error of a regression model. The function should take in two lists, one that represents the predictions and another with the target values. (Snapchat | Roles: Data Scientist, ML Engineer)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLPJ0u-dGPgv"
      },
      "source": [
        "import math\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    if len(y_true) != len(y_pred):\n",
        "        print(\"Length doesn't match\")\n",
        "        return\n",
        "    sq = sum((x - y)**2 for x, y in zip(y_true, y_pred))\n",
        "    output_rmse = math.sqrt(sq / len(y_true))\n",
        "    return output_rmse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGF5Z8TAGY2Q"
      },
      "source": [
        "9. Let’s say we have a five-by-five matrix where each row is a company and each column represents a department. Each cell of the matrix displays the number of employees working in that particular department at each company.\n",
        "Write a program to return a five by five matrix that contains the percentage of employees employed in each department compared to the total number of employees at each company. (Google | Data Scientist)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXIOPwlJGVzV",
        "outputId": "29366c2e-6606-4601-bf73-da7babc1291d"
      },
      "source": [
        "employees_by_department=[\n",
        "    [10, 20, 30, 30, 10], \n",
        "    [15, 15, 5, 10, 5], \n",
        "    [150, 50, 100, 150, 50], \n",
        "    [300, 200, 300, 100, 100], \n",
        "    [1, 5, 1, 1, 2]\n",
        "]\n",
        "a = []\n",
        "for row in employees_by_department:\n",
        "    row_sum = 0\n",
        "    for j in row:\n",
        "        row_sum += j\n",
        "    new_row = [j/row_sum for j in row]\n",
        "    a.append(new_row)\n",
        "print(\"percentage_by_department =\",a)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage_by_department = [[0.1, 0.2, 0.3, 0.3, 0.1], [0.3, 0.3, 0.1, 0.2, 0.1], [0.3, 0.1, 0.2, 0.3, 0.1], [0.3, 0.2, 0.3, 0.1, 0.1], [0.1, 0.5, 0.1, 0.1, 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id-ZMj1kGfF8"
      },
      "source": [
        "10. Matrix Transpose\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g54L7iARGc8L",
        "outputId": "d7368e90-7c33-43a3-8293-6023a75ab9fc"
      },
      "source": [
        "matrix=[\n",
        "[1, 2, 3, 4],\n",
        "[5, 6, 7, 8],\n",
        "[9, 10, 11, 12]\n",
        "]\n",
        "transposed=[[row[i] for row in matrix] for i in range(4)]\n",
        "print(transposed)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxTzJQPEGmt_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}